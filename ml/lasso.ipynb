{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO全称为The Least Absolute Shrinkage and Selection Operator, 是一种特征选择的方法，经过LASSO处理之后，就能知道训练样本的所有特征中哪些是有效特征。对于无效特征，其对应的权重为0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO的实际上是一种[线性回归](linear_regression.ipynb), 它在线性回归目标函数的基础上添加一个约束$\\displaystyle\\sum_{i = 1}^n|w_i| \\le t$(也可以认为是在其目标函数上添加了$L_1$[正则](regularization.ipynb)，这是等价的)。这样在优化目标函数的时候，会有许多$w_i$取值为0。在添加约束之后，其优化的目标函数变成\n",
    "$$\n",
    "\\underset{W, b}{arg\\ min} \\displaystyle\\sum_{i = 1}^N (W^Tx_i + b -y_i)^2  + \\lambda\\|W\\|_1\\tag{1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察目标函数可知，目标函数并不处处可导，那么其优化方式不能使用梯度下降。如果想要使用梯度下降法模型优化，可以使用如下的假设\n",
    "$$\n",
    "L_1(w) =\\displaystyle\\sum_{d = 1}^D\\sqrt{w^2 + \\varepsilon}\n",
    "\\tag{2}\n",
    "$$\n",
    "使用公式(2)代替公式(1)的右半部分后就可以使用梯度下降法、牛顿法等依靠梯度优化的方法\n",
    "\n",
    "当然，优化LASSO的方法非常多，本笔记仅将详细的描述坐标下降法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinate Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "坐标下降法每次针对一个属性进行更新，我们假设数据集有m个属性，n个样例，数据矩阵为$m \\times n$ 的矩阵，那么目标函数为：\n",
    "$$\n",
    "W^* = \\underset{W}{arg\\ min} \\displaystyle\\sum_{i = 1}^n\\bigg(y_i - \\sum_{j= 1}^mx_{ij}W_j\\bigg)^2 + \n",
    "\\lambda\\sum_{j=1}^m|W_j|\\tag{3}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设现在沿着第$k$个维度做优化，对其求偏导有：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial L}{\\partial W_k} \n",
    "=& \\displaystyle\\sum_{i = 1}^n-2x_{ik}\\Big(y_i - \\sum_{j = 1}^mx_{ij}W_j\\Big) + \n",
    "\\begin{cases}\n",
    "\\lambda & W_k > 0\\\\ \n",
    "[-\\lambda, \\lambda] & W_k = 0\\\\\n",
    "-\\lambda  &W_k < 0\n",
    "\\end{cases}\\\\\n",
    "=& -2\\displaystyle\\sum_{i = 1}^nx_{ik}\\Big(y_i - \\sum_{j\\not= k}^m x_{ij}W_j\\Big) + 2W_k\\sum_{i = 1}^nx_{ik}^2 + \n",
    "\\begin{cases}\n",
    "\\lambda & W_k > 0\\\\ \n",
    "[-\\lambda, \\lambda] & W_k = 0\\\\\n",
    "-\\lambda  &W_k < 0\n",
    "\\end{cases}\\\\\n",
    "\\end{aligned}\\tag{4}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p_k =& -2\\displaystyle\\sum_{i = 1}^nx_{ik}\\Big(y_i - \\sum_{j\\not= k}^m x_{ij}W_j\\Big) \\\\\n",
    "m_k =& 2W_k\\sum_{i = 1}^nx_{ik}^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么公式(4)可以写作\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial W_k}  = \n",
    "p_k + m_kW_k + \n",
    "\\begin{cases}\n",
    "\\lambda & W_k > 0\\\\ \n",
    "[-\\lambda, \\lambda] & W_k = 0\\\\\n",
    "-\\lambda  &W_k < 0\n",
    "\\end{cases}\n",
    "\\tag{5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "推导成这样的形式是因为这是对$W_k$的偏导。令偏导数为0得到极值，暂时先不考虑$W_k = 0$的情况，那么令偏导等于0就有\n",
    "$$\n",
    "p_k + m_kW^*_k + \\lambda sign(W_k^*) = 0\\tag{6}\n",
    "$$\n",
    "$$\n",
    "W_k^* + \\frac{1}{m_k}(p_k + \\lambda sign(W_k^*)) = 0\\tag{7}\n",
    "$$\n",
    "找出能满足方程的$w^*_k$即可找到极值点，这种情况只能分类讨论，首先明确$m_k  >0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 当$p_k > \\lambda$时：\n",
    "\n",
    "   - 若$W_k^* > 0$时，$W_k^* + \\frac{1}{m_k}(p_k + \\lambda sign(W_k^*)) = 0$不可能，两个正数之和不可能为0；\n",
    "\n",
    "   - 若$W_k^* < 0$时，$W_k^* + \\frac{1}{m_k}(p_k + \\lambda sign(W_k^*)) = 0$合理，因为一正一负；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 当$p_k < -\\lambda$时：\n",
    "\t - 若$W_k^* > 0$时，$W_k^* + \\frac{1}{m_k}(p_k + \\lambda sign(W_k^*)) = 0$ 合理，因为一正一负；\n",
    "\t - 若$W_k^* < 0$时，$W_k^* + \\frac{1}{m_k}(p_k + \\lambda sign(W_k^*)) = 0$ 不可能，两个负数之和不可能为0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 当$-\\lambda \\le p_k \\le \\lambda$时，无论$W_k^* > 0$或者$W_k^* < 0$均不可能成立，故考虑$W_k^* = 0$，\n",
    "\n",
    "就这样得出了一个闭合解:\n",
    "$$\n",
    "W_k^* = \n",
    "\\begin{cases}\n",
    "-\\frac{1}{m_k}(p_K - \\lambda) & p_k > \\lambda\\\\\n",
    "-\\frac{1}{m_k}(p_K + \\lambda) & p_k < - \\lambda\\\\\n",
    "0\n",
    "\\end{cases}\\tag{8}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本模型的[示例](../code/ml/6_lasso.ipynb)就是使用coordinate descent实现的。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
